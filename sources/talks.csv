title	type	url_slug	venue	date	location	talk_url	description
100° Nexa Lunch Seminar. Produzione etica dei dataset per l'intelligenza artificiale: il ruolo della documentazione	Talk	nexa-lunch-100-etica-dataset-documentazione	Nexa Center for Internet & Society	2022-09-28	Torino, Italy	https://nexa.polito.it/lunch-100	"100° Nexa Lunch Seminar.

La ricerca e lo sviluppo industriale dell'intelligenza artificiale hanno fatto passi da gigante negli ultimi anni, rendendo le tecnologie basate su di essa sempre più pervasive all'interno della società (anche in settori molto delicati come welfare, giustizia, credito, etc) e contribuendo ad automatizzare processi e decisioni. Uno degli elementi chiave alla base dell'IA sono i dati, i quali spesso determinano la qualità dei risultati ottenuti.

Per questo è sempre più importante far sì che i professionisti dell'IA siano pienamente consapevoli delle caratteristiche dei dati e dei processi che li hanno generati, comprese le scelte progettuali più o meno implicite e basate su presupposti tutt'altro che neutri. La documentazione dei dataset può rappresentare uno strumento molto utile in questa prospettiva. Essa rappresenta la principale forma di comunicazione tra produttori e utilizzatori dei dataset, in grado di rendere trasparente il contesto attorno il quale i dati sono stati raccolti, annotati e trasformati.

In questa ricerca è stato individuato un insieme di informazioni rilevanti che dovrebbero sempre essere allegate ad un dataset per garantirne un utilizzo consapevole. In secondo luogo, sono state analizzate le documentazioni dei 100 dataset più popolari tra alcune delle principali piattaforme del settore al fine di valutarne la completezza. Quello che emerge è la necessità di una maggiore attenzione al processo di documentazione, anche per garantire risultati più equi."
Data Quality, Data Balance and Data Documentation: a framework	Student Symposium talk	student-symposium-data-quality-balance-documentation-framework	22nd Portuguese Conference on Artificial Intelligence (EPIA23)	2023-09-05	Horta, Faial Island, Azores, PT	https://epia2023.inesctec.pt/?page_id=1782	"To promote the responsible development and use of artificial intelligence (AI), principles of trustworthiness, accountability and fairness should be followed.  These principles can be threatened by various ethical challenges. Several approaches can be used, such as working at the data level, as data is one of the key elements of the AI pipeline. 

However, ensuring high data quality alone is not sufficient to avoid all ethical concerns. Expanding data quality frameworks to include data balance and data documentation can be helpful in addressing critical aspects of ethical considerations related to AI systems. The proposed framework introduces additional quality measures, such as the assessment of data balance and the quality of data documentation. The former can be useful to identify risks of disproportionate treatment of different groups based on their protected characteristics.  The latter emphasises the importance of documenting datasets, making them more transparent and accountable. 

By integrating these measures into the development pipeline through appropriate data labels, we aim to empower practitioners to build more responsible systems. We outline future research directions for automating these metric evaluation processes.  "
Completeness of datasets documentation on ML/AI repositories: an empirical investigation	Conference proceedings talk	completeness-dataset-documentation-investigation	22nd Portuguese Conference on Artificial Intelligence (EPIA23)	2023-09-07	Horta, Faial Island, Azores, PT	https://epia2023.inesctec.pt/?page_id=1782	"ML/AI is the field of computer science and computer engineering that arguably received the most attention and funding over the last decade. Data is the key element of ML/AI, so it is becoming increasingly important to ensure that users are fully aware of the quality of the datasets that they use, and of the process generating them, so that possible negative impacts on downstream effects can be tracked, analysed, and, where possible, mitigated. One of the tools that can be useful in this perspective is dataset documentation. 

The aim of this work is to investigate the state of dataset documentation practices, measuring the completeness of the documentation of several popular datasets in ML/AI repositories. We created a dataset documentation schema—the Documentation Test Sheet (DTS)—that identifies the information that should always be attached to a dataset (to ensure proper dataset choice and informed use), according to relevant studies in the literature. We verified 100 popular datasets from four different repositories with the DTS to investigate which information were present.  

Overall, we observed a lack of relevant documentation, especially about the context of data collection and data processing, highlighting a paucity of transparency. "
Facial Analysis Systems and Down Syndrome	Conference proceedings talk	facial-analysis-systems-down-syndrome	3rd Workshop on Bias and Fairness in AI - BIAS 2023 @ European Conference on Machine Learning and Principles and Practice of Knowledge Discovery (ECML PKDD 2023)	2023-09-22	Torino, Italy	https://sites.google.com/view/bias2023/program	"The ethical, social and legal issues surrounding facial analysis technologies have been widely debated in recent years. Key critics have argued that these technologies can perpetuate bias and discrimination, particularly against marginalized groups. We contribute to this field by reporting on the limitations of facial analysis systems with the faces of people with Down syndrome: this particularly vulnerable group has received very little attention in the literature so far. 

This study involved the creation of a specific dataset of face images. An experimental group with faces of people with Down syndrome, and a control group with faces of people who are not affected by the syndrome. Two commercial tools were tested on the dataset, along three tasks: gender recognition, age prediction and face labelling. 

The results show an overall lower prediction accuracy in the experimental group, and other performance differences: i) high error rates in gender recognition in the category of males with Down syndrome; ii) adults with Down syndrome can be mislabelled as children; iii) social stereotypes are propagated in both the control and experimental groups, with labels related to aesthetics more often associated with females, and labels related to education level and ability more often associated with males.

These results, although limited in scope, shed new light on the biases that alter face classification when applied to faces of people with Down syndrome.  They confirm the structural limitation of the technology, which is inherently dependent on the datasets used to train the models."
Testing software for non-discrimination: an updated and extended audit in the Italian car insurance domain	Conference proceedings talk	faiema-2024-testing-discrimination	2nd International Conference on Frontiers of Artificial Intelligence, Ethics, and Multidisciplinary Applications (FAIEMA24)	2024-10-01	Athens, Greece	https://www.faiema.org/	
Responsible development and use of AI: a metric-based framework for enabling empirical evaluations	Student symposium talk	idoese-2024-responsibe-ai	International Doctoral Symposium on Empirical Software Engineering (IDoESE 2024)	2024-10-23	Barcelona, Spain	https://conf.researchr.org/track/esem-2024/esem-2024-doctoral-symposium	