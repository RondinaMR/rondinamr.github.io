pub_date	title	venue	excerpt	citation	url_slug	paper_url	authors	pdf_url
2023-07-03	Designing Logic Tensor Networks for Visual Sudoku puzzle classification	17th International Workshop on Neural-Symbolic Learning and Reasoning (NeSy 2023)	Given the increasing importance of the neurosymbolic (NeSy) approach in artificial intelligence, there is a growing interest in studying benchmarks specifically designed to emphasize the ability of AI systems to combine low-level representation learning with high-level symbolic reasoning. One such recent benchmark is Visual Sudoku Puzzle Classification, that combines visual perception with relational constraints. In this work, we investigate the application of Logic Tensork Networks (LTNs) to the Visual Sudoku Classification task and discuss various alternatives in terms of logical constraint formulation, integration with the perceptual module and training procedure. 	Designing Logic Tensor Networks for Visual Sudoku puzzle classification / Morra, Lia; Azzari, Alberto; Bergamasco, Letizia; Braga, Marco; Capogrosso, Luigi; Delrio, Federico; DI GIACOMO, Giuseppe; Eiraudo, Simone; Ghione, Giorgia; Giudice, Rocco; Koudounas, Alkis; Piano, Luca; REGE CAMBRIN, Daniele; Risso, Matteo; Rondina, Marco; Russo, ALESSANDRO SEBASTIAN; Russo, Marco; Taioli, Francesco; Vaiani, Lorenzo; Vercellino, Chiara. - ELETTRONICO. - 3432:(2023), pp. 223-232. (Intervento presentato al convegno 17th International Workshop on Neural-Symbolic Learning and Reasoning (NeSy 2023) tenutosi a Certosa di Pontignano, Siena (Italia) nel July 3-5, 2023).	designing-logic-tensor-networks-for-visual-sudoku-puzzle-classification	https://hdl.handle.net/11583/2978475	Lia Morra, Alberto Azzari, Letizia Bergamasco, Marco Braga, Luigi Capogrosso, Federico Delrio, Giuseppe Di Giacomo, Simone Eiraudo, Giorgia Ghione, Rocce Giudice, Alkis Koudounas, Luca Piano, Daniele Cambrin Rege, Matteo Risso, Marco Rondina, Sebastian Alessandro, Marco Russo, Francesco Taioli, lorenzo Vaiani, Chiara Vercellino	
2023-09-05	Completeness of Datasets Documentation on ML/AI Repositories: An Empirical Investigation	22nd Portuguese Conference on Artificial Intelligence (EPIA 2023)	ML/AI is the field of computer science and computer engineering that arguably received the most attention and funding over the last decade. Data is the key element of ML/AI, so it is becoming increasingly important to ensure that users are fully aware of the quality of the datasets that they use, and of the process generating them, so that possible negative impacts on downstream effects can be tracked, analysed, and, where possible, mitigated. One of the tools that can be useful in this perspective is dataset documentation. The aim of this work is to investigate the state of dataset documentation practices, measuring the completeness of the documentation of several popular datasets in ML/AI repositories. We created a dataset documentation schema-the Documentation Test Sheet (dts)-that identifies the information that should always be attached to a dataset (to ensure proper dataset choice and informed use), according to relevant studies in the literature. We verified 100 popular datasets from four different repositories with the dts to investigate which information were present. Overall, we observed a lack of relevant documentation, especially about the context of data collection and data processing, highlighting a paucity of transparency. 	Completeness of Datasets Documentation on ML/AI Repositories: An Empirical Investigation / Rondina, Marco; Vetro', Antonio; De Martin, Juan Carlos. - 14115:(2023), pp. 79-91. (Intervento presentato al convegno 22nd Portuguese Conference on Artificial Intelligence tenutosi a Horta, Faial Island, Azores nel September 5 – September 8, 2023) [10.1007/978-3-031-49008-8_7].	completeness-datasets-documentation-mlai-repositories	https://hdl.handle.net/11583/2981538	Marco Rondina, Antonio Vetro’, Juan Carlos De Martin	http://rondinamr.github.io/files/01-1_dts_postprint.pdf
2023-09-18	Facial Analysis Systems and Down Syndrome	European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD 2023) - 3rd Workshop on Bias and Fairness in AI (BIAS23). In press.	The ethical, social and legal issues surrounding facial analysis technologies have been widely debated in recent years. Key critics have argued that these technologies can perpetuate bias and discrimination, particularly against marginalized groups. We contribute to this field by reporting on the limitations of facial analysis systems with the faces of people with Down syndrome: this particularly vulnerable group has received very little attention in the literature so far.  This study involved the creation of a specific dataset of face images. An experimental group with faces of people with Down syndrome, and a control group with faces of people who are not affected by the syndrome. Two commercial tools were tested on the dataset, along three tasks: gender recognition, age prediction and face labelling.  The results show an overall lower prediction accuracy in the experimental group, and other performance differences: i) high error rates in gender recognition in the category of males with Down syndrome; ii) adults with Down syndrome can be mislabelled as children; iii) social stereotypes are propagated in both the control and experimental groups, with labels related to aesthetics more often associated with females, and labels related to education level and ability more often associated with males.  These results, although limited in scope, shed new light on the biases that alter face classification when applied to faces of people with Down syndrome. They confirm the structural limitation of the technology, which is inherently dependent on the datasets used to train the models.	Facial Analysis Systems and Down Syndrome / Rondina, Marco; Vinci, Fabiana; Vetro', Antonio; DE MARTIN, JUAN CARLOS. - (In corso di stampa). (Intervento presentato al convegno European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases - 3rd Workshop on Bias and Fairness in AI tenutosi a Torino (IT) nel September 18-22, 2023).	facial-analysis-systems-down-syndrome	https://hdl.handle.net/11583/2982543	Marco Rondina, Fabiana Vinci, Antonio Vetro', Juan Carlos De Martin	https://rondinamr.github.io/files/03-1_fas-ds_postprint.pdf
2024-10-01	Testing software for non-discrimination: an updated and extended audit in the Italian car insurance domain	2nd International Conference on Frontiers of Artificial Intelligence, Ethics, and Multidisciplinary Applications; 1st - 2nd October 2024; Athens, Greece.	"<b>Context</b>. As software systems become more integrated into society’s infrastructure, the responsibility of software professionals to ensure compliance with various non-functional requirements increases. These requirements include security, safety, privacy, and, increasingly, non-discrimination.
<b>Motivation</b>. Fairness in pricing algorithms grants equitable access to basic services without discriminating on the basis of protected attributes. 
<b>Method</b>. We replicate a previous empirical study that used black box testing to audit pricing algorithms used by Italian car insurance companies, accessible through a popular online comparator website. With respect to the previous study, we enlarged the number of tests and the number of demographic variables under analysis.  
<b>Results</b>. Our work confirms and extends previous findings, highlighting the problematic permanence of discrimination across time: demographic variables significantly impact pricing to this day, with birthplace remaining the main discriminatory factor against individuals not born in Italian cities. We also found that driver profiles can determine the number of quotes available to the user, denying equal opportunities to all.   
<b>Conclusion</b>. The study underscores the importance of testing for non-discrimination in software systems that affect people's everyday lives. Performing algorithmic audits over time makes it possible to evaluate the evolution of such algorithms. It also demonstrates the role that empirical software engineering can play in making software systems more accountable. "	Testing software for non-discrimination: an updated and extended audit in the Italian car insurance domain / Rondina, Marco; Vetro', Antonio; Coppola, Riccardo; Regragui, Oumaima; Fabris, Alessandro; Silvello, Gianmaria; Susto, Gian Antonio; De Martin, Juan Carlos. - (In corso di stampa). (Intervento presentato al convegno 2nd International Conference on Frontiers of Artificial Intelligence, Ethics, and Multidisciplinary Applications tenutosi a Athens (Greece) nel 1st - 2nd October 2024).	Testing-software-non-discrimination-updated-extended-audit-italian-car-insurance	https://hdl.handle.net/11583/2992086	Marco Rondina, Antonio Vetro’, Riccardo Coppola, Oumaima Regragui, Alessandro Fabris, Gianmaria Silvello, Gian Antonio Susto, Juan Carlos De Martin	https://rondinamr.github.io/files/06-rca_2-postprint_TestingSoftwareforNonDiscrimination.pdf
